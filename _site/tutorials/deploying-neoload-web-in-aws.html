<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Deploying NeoLoad Web in AWS | Neotys Connect</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Deploying NeoLoad Web in AWS" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Community-driven tutorials, learning resources, and collaborations on the NeoLoad Platform." />
<meta property="og:description" content="Community-driven tutorials, learning resources, and collaborations on the NeoLoad Platform." />
<link rel="canonical" href="https://connect.neotys.com/tutorials/deploying-neoload-web-in-aws" />
<meta property="og:url" content="https://connect.neotys.com/tutorials/deploying-neoload-web-in-aws" />
<meta property="og:site_name" content="Neotys Connect" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Deploying NeoLoad Web in AWS" />
<script type="application/ld+json">
{"@type":"WebPage","headline":"Deploying NeoLoad Web in AWS","description":"Community-driven tutorials, learning resources, and collaborations on the NeoLoad Platform.","url":"https://connect.neotys.com/tutorials/deploying-neoload-web-in-aws","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://connect.neotys.com/feed.xml" title="Neotys Connect" />
</head>
<body><header class="site-header">

  <div class="wrapper"><div style="display:flex;align-items:flex-end;float:left;">
      <a class="site-title" style="padding-right:0.8em;white-space: nowrap;" rel="author" href="/">Neotys Connect</a>
      <span style="float:left;color:#ccc;max-width:350px;line-height:1em;margin-right:2em;padding-bottom:0.5em;font-size:1em;">Community-driven tutorials, learning resources, and collaborations on the NeoLoad Platform.</span>
    </div><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/tutorials/">Tutorials</a><a class="page-link" href="/get-involved/">Get Involved</a></div>
      </nav></div>
</header>
<div>
        <div class="wrapper"><div id="breadcrumbs">

<a href="/">Home</a>

  
    / <a href="/tutorials/">Tutorials</a>
  

  
    / Deploying NeoLoad Web in AWS
  

</div>
</div>
      </div><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">








  <div class="article-content-with-sidebar">



<header class="post-header">
  <h1 class="post-title">Deploying NeoLoad Web in AWS</h1>
</header>

<h1 id="the-short-version">The Short Version</h1>

<p>See <a href="https://github.com/neotys-connect/neoload_kube/tree/master/aws" target="_blank">this neoload_kube repo</a> for the TL;DR version of EKS setup and configuration.</p>

<h1 id="the-complete-walkthrough">The Complete Walkthrough</h1>

<p>The purpose of this document is to describe the steps needed to install Neoload Web as a stand-alone private cloud implementation. This is for Neotys customers who may need to use an on-premise installation, in addition to the publicly available SaaS version provided by Neotys at <a href="https://neoload.saas.neotys.com/">https://neoload.saas.neotys.com/</a></p>

<p>These instructions are specific to implementing Neoload Web as a managed Kubernetes cluster using Amazon AWS cloud, and specifically the Elastic Kubernetes Service (EKS) for the deployment.</p>

<h1 id="before-you-begin">Before you begin</h1>

<p>Neotys is expecting that anyone attempting to set this up already has experience with AWS cloud services, Kubernetes, Docker, YAML, mongodb, and the various CLI’s mentioned in this documentation. Neotys has provided online documentation through their web site and github repositories to help with Neoload specific tasks, but building out the infrastructure and services around the solution are the responsibility of the implementation person. This document is an attempt to help provide further guidance and make the process as easy as possible, but some experience by the user will be necessary to address unknown issues that may arise.</p>

<p>You will need the following:</p>

<ol>
  <li>Amazon Account with permissions to do everything in this article</li>
  <li>The ability to route DNS records</li>
  <li>An understanding of network routing on AWS, including setting up Application Load Balancers</li>
  <li>The ability to setup a mongodb database, either as a cloud SaaS version at <a href="https://www.mongodb.com/cloud/atlas">https://www.mongodb.com/cloud/atlas</a>, or a stand alone version on a virtual/physical machine.</li>
  <li>For one time setup, there are several programs and command line interface applications (CLI’s) that should be installed on your local machine. You will need permission to install and configure these.</li>
</ol>

<p>For these examples, we are using the MacOS operating. If you are using another OS such as Windows or Linux, you will need to research the alternative commands and information online.</p>

<h1 id="what-is-amazon-eks">What is Amazon EKS?</h1>

<p>Amazon Elastic Kubernetes Service (EKS) is a managed Kubernetes service that makes it easy for you to run Kubernetes on AWS without needing to install, operate, and maintain your own Kubernetes control plane.</p>

<p><a href="https://aws.amazon.com/eks/features/">https://aws.amazon.com/eks/features/</a></p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image3.png" alt="alt_text" title="image_tooltip" /></p>

<p>There is no way we can walk through every aspect of creating and setting up an AWS account. To keep the scope reasonable, we have provided links to the basics that need to be done before moving on.</p>

<p><strong>Set up an AWS account:</strong> <a href="https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/">https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/</a></p>

<p>**Create SSH keypair: **<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html</a></p>

<p><strong>Elastic Kubernetes Service (EKS) Cheat Sheet:</strong></p>

<p><a href="https://theaws.blog/elastic-kubernetes-service-eks-cheat-sheet/">https://theaws.blog/elastic-kubernetes-service-eks-cheat-sheet/</a></p>

<h1 id="cli-and-prerequisite-installation">CLI and Prerequisite Installation</h1>

<h2 id="aws-cli-v2">AWS CLI v2</h2>

<p>Install Python 3.7+, required for AWS CLI v2</p>

<p><a href="https://docs.python-guide.org/starting/install3/osx/">https://docs.python-guide.org/starting/install3/osx/</a></p>

<blockquote>
  <blockquote>
    <p>python –version</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Python 3.9.0
</code></pre></div></div>

<p>Install and configure the AWS CLI v2</p>

<p><a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html">https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html</a></p>

<blockquote>
  <blockquote>
    <p>brew install awscli</p>
  </blockquote>
</blockquote>

<p>Verify you are using the right version:</p>

<blockquote>
  <blockquote>
    <p>aws –version</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws-cli/2.0.59 ...
</code></pre></div></div>

<p>Log in to your AWS account via:</p>

<blockquote>
  <blockquote>
    <p>aws configure</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AWS Access Key ID [****************redacted]: &lt;enter key Id&gt;

AWS Secret Access Key [****************redacted]: &lt;enter access key&gt;

Default region name [us-east-2]: &lt;or choose another region&gt;

Default output format [json]: &lt;or choose another format&gt;
</code></pre></div></div>

<p>Make sure that you can run</p>

<p>aws eks list-clusters</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{

    "clusters": [

        "nlw"

    ]

}
</code></pre></div></div>

<p>(You may not have any listed yet.)</p>

<p>AWS CLI cheat sheet: <a href="https://devhints.io/awscli">https://devhints.io/awscli</a></p>

<h2 id="helm">helm</h2>

<p><a href="https://helm.sh/docs/intro/install/">https://helm.sh/docs/intro/install/</a></p>

<p>For MacOS:</p>

<p>brew install helm</p>

<blockquote>
  <blockquote>
    <p>helm version</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version.BuildInfo{Version:"v3.4.1", GitCommit:"redacted", GitTreeState:"dirty", GoVersion:"go1.15.4"}
</code></pre></div></div>

<h2 id="eksctl-and-kubectl">eksctl and kubectl</h2>

<p>Install and configure AWS ‘eksctl’</p>

<p><a href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html">https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html</a></p>

<blockquote>
  <blockquote>
    <p>eksctl version</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.32.0
</code></pre></div></div>

<blockquote>
  <blockquote>
    <p>kubectl version</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Client Version: version.Info{Major:"1", Minor:"19", GitVersion:"v1.19.4", GitCommit:"redacted", GitTreeState:"clean", BuildDate:"2020-11-12T01:09:16Z", GoVersion:"go1.15.4", Compiler:"gc", Platform:"darwin/amd64"}

Server Version: version.Info{Major:"1", Minor:"18+", GitVersion:"v1.18.9-eks-d1db3c", GitCommit:"redacted", GitTreeState:"clean", BuildDate:"2020-10-20T22:18:07Z", GoVersion:"go1.13.15", Compiler:"gc", Platform:"linux/amd64"}
</code></pre></div></div>

<blockquote>
  <blockquote>
    <p>kubectl config get-contexts</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CURRENT   NAME                             CLUSTER                   AUTHINFO                         NAMESPACE

*         smoore@nlw.us-east-2.eksctl.io   nlw.us-east-2.eksctl.io   smoore@nlw.us-east-2.eksctl.io   
</code></pre></div></div>

<blockquote>
  <blockquote>
    <p>kubectl config current-context</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smoore@nlw.us-east-2.eksctl.io
</code></pre></div></div>

<blockquote>
  <blockquote>
    <p>kubectl cluster-info</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Kubernetes master is running at https://redacted.yl4.us-east-2.eks.amazonaws.com

CoreDNS is running at https://redacted.yl4.us-east-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
</code></pre></div></div>

<blockquote>
  <blockquote>
    <p>eksctl get cluster</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME	REGION		EKSCTL CREATED

nlw	us-east-2	True
</code></pre></div></div>

<p>(You may not have any clusters yet.)</p>

<p>This guide makes a best effort to provide the main commands to accomplish the task of setting up the Neoload Web cluster. However, things don’t always go as expected. For this reason, it is advisable to get some level of training using eksctl and know what the commands are actually doing. Training in Kubernetes in general is also recommended. The following link provides basic information on some of the most used eksctl commands.</p>

<p><strong>kubectl commands cheat sheet:</strong></p>

<p><a href="https://drive.google.com/file/d/1Fd1Yq5uyWDxnx-9U2xMe2WsjP2x05xbu/view?usp=sharing">https://drive.google.com/file/d/1Fd1Yq5uyWDxnx-9U2xMe2WsjP2x05xbu/view?usp=sharing</a></p>

<h1 id="neoload-web">Neoload Web</h1>

<p>NeoLoad Web is the centralized Performance Testing Platform designed for Continuous Testing. You can do the following:</p>

<ul>
  <li>Launch performance tests</li>
  <li>Select your load generation infrastructure</li>
  <li>Analyse test results in real time or for terminated tests</li>
  <li>Customize dashboards, based on custom graphs</li>
  <li>Share performance test results with Dev, QA, Ops</li>
  <li>Connect performance testing data: import and correlate third party data / export NeoLoad test data</li>
</ul>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image4.png" alt="alt_text" title="image_tooltip" /></p>

<p><strong>About Neoload Web</strong></p>

<p><a href="https://www.neotys.com/neoload/features/neoload-web">https://www.neotys.com/neoload/features/neoload-web</a></p>

<p>The main thing we want to do is have our own stand-alone installation instead of being restricted to X hours per month for the Neotys SaaS version. We want other team members to be able to watch tests run and share test results. We also want to be able to put ZIP’ed projects and YAML-based tests (like API direct calls) uploaded into Neoload Web for test execution.</p>

<p><strong>Neoload Official Documentation</strong></p>

<p><a href="https://www.neotys.com/documents/doc/nlweb/latest/en/html/#2983.htm">https://www.neotys.com/documents/doc/nlweb/latest/en/html/#2983.htm</a></p>

<p><strong>Docker Deployment of Neoload Web with external MongoDB</strong></p>

<p><a href="https://www.neotys.com/documents/doc/nlweb/latest/en/html/#26078.htm">https://www.neotys.com/documents/doc/nlweb/latest/en/html/#26078.htm</a> - this document describes creating a dockerized installation with a separate Mongodb. We will be doing this with a Helm chart, but the concept and configuration is similar.</p>

<h1 id="deploy-neoload-web">Deploy Neoload Web</h1>

<p>Neoload AWS KUBE deployment documentation:</p>

<p><a href="https://github.com/paulsbruce/neoload_kube/blob/master/aws/nlw_deploy_eks.md">https://github.com/paulsbruce/neoload_kube/blob/master/aws/nlw_deploy_eks.md</a></p>

<p>This is what we are trying to build:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image5.png" alt="alt_text" title="image_tooltip" /></p>

<p>This diagram shows that we will be accessing a custom domain for Neoload Web, and these requests will be routed to the Neoload Web Cluster (NLW Cluster above). This will access the front end (FE) web server which is the web UI for Neoload Web. The back end (BE) is the programming logic that communicates to the back end Mongo database - which we are creating as a Mongo Atlas database in the cloud from Mongo (this is an additional service set up outside of AWS, but the actual database runs on AWS infrastructure). Both the FE and BE are running as docker containers in the EKS cluster.</p>

<p>The Load Cluster listed in the diagram is a separate EKS cluster that will hold all of the Controller and Load Generator machines. Setting up this cluster is outside of the scope of this document, but the purpose of the cluster is to be a place for all of the Neoload lab infrastructure to be accessible on demand as needed (when tests are executed). This cluster could be replaced with Dockerized containers running inside of a virtual machine, a generator (non-docker) installed on virtual machines, or generator (non-docker) installed directly on physical machines. Any of this can connect to the Neoload Web Cluster. If you are interested in setting up a second cluster for dynamic infrastructure on AWS using the Fargate service, see this URL:</p>

<p><a href="https://github.com/paulsbruce/neoload_kube/tree/master/aws">https://github.com/paulsbruce/neoload_kube/tree/master/aws</a></p>

<p>Note that the dynamic infrastructure features require an Enterprise license of Neoload.</p>

<h2 id="create-the-eks-cluster">Create The EKS Cluster</h2>

<p>We could set the cluster using the AWS web site. However, this UI is always changing over time, and the instructions have to be maintained. Using a CLI allows for many tasks to be completed for setup and configuration with a few commands.</p>

<p>You have to create a node group with at least one node. We want to size the node so that it matches the Neoload documentation for hardware specifications. I suggest md5.xlarge. We will create this on us-east-2, but you may want to create this on the same region as the application under test.</p>

<p>Instead of just using command line arguments, we will use a YAML file to define the arguments and make it easier to execute. We will use a custom YAML file to create the Neoload Web Cluster. Here is an example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># An example of ClusterConfig with a normal nodegroup
---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
 name: nlw
 region: us-east-2

vpc:
 cidr: 172.16.0.0/16

nodeGroups:
- name: ng-1
 instanceType: m5.xlarge
 desiredCapacity: 1
 volumeSize: 20
 privateNetworking: true
</code></pre></div></div>

<p>This example specifically uses a 172.16/12 CIDR that is compatible with Mongo Atlas. <a href="https://docs.atlas.mongodb.com/security-vpc-peering/">https://docs.atlas.mongodb.com/security-vpc-peering/</a> - see the section labeled “VPC CIDR”.</p>

<p>The AWS VPC CIDR block or subset cannot overlap with your Atlas CIDR Block or any other Network Peering connection VPC CIDR.</p>

<p>The CIDR block must be in one of the following private networks:</p>

<ul>
  <li><strong>10.0.0.0 - 10.255.255.255</strong> (10/8 prefix)</li>
  <li><strong>172.16.0.0 - 172.31.255.255</strong> (172.16/12 prefix)</li>
  <li><strong>192.168.0.0 - 192.168.255.255</strong> (192.168/16 prefix)</li>
</ul>

<p>You can choose to add the VPC CIDR block address (or a subset) to the IP access list. For Network Peering connections, you can also add the Security Group associated with the AWS VPC instead of the CIDR block.</p>

<p>Here is an example of running the eksctl create cluster command referencing the custom YAML file and what comes back from AWS:</p>

<blockquote>
  <blockquote>
    <p>eksctl create cluster -f /Users/smcllc/ekscluster-nlw.yaml</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ℹ]  eksctl version 0.32.0
[ℹ]  using region us-east-2
[ℹ]  setting availability zones to [us-east-2a us-east-2b us-east-2c]
[ℹ]  subnets for us-east-2a - public:172.redacted/19 private:172.redacted/19
[ℹ]  subnets for us-east-2b - public:172.redacted/19 private:172.redacted/19
[ℹ]  subnets for us-east-2c - public:172.redacted/19 private:172.redacted/19
[ℹ]  nodegroup "ng-1" will use "ami-redacted" [AmazonLinux2/1.18]
[ℹ]  using Kubernetes version 1.18
[ℹ]  creating EKS cluster "nlw" in "us-east-2" region with un-managed nodes
[ℹ]  1 nodegroup (ng-1) was included (based on the include/exclude rules)
[ℹ]  will create a CloudFormation stack for cluster itself and 1 nodegroup stack(s)
[ℹ]  will create a CloudFormation stack for cluster itself and 0 managed nodegroup stack(s)
[ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-2 --cluster=nlw'
[ℹ]  CloudWatch logging will not be enabled for cluster "nlw" in "us-east-2"
[ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=us-east-2 --cluster=nlw'
[ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "nlw" in "us-east-2"
[ℹ]  2 sequential tasks: { create cluster control plane "nlw", 2 sequential sub-tasks: { no tasks, create nodegroup "ng-1" } }
[ℹ]  building cluster stack "eksctl-nlw-cluster"
[ℹ]  deploying stack "eksctl-nlw-cluster"
[ℹ]  building nodegroup stack "eksctl-nlw-nodegroup-ng-1"
[ℹ]  --nodes-min=1 was set automatically for nodegroup ng-1
[ℹ]  --nodes-max=1 was set automatically for nodegroup ng-1
[ℹ]  deploying stack "eksctl-nlw-nodegroup-ng-1"
[ℹ]  waiting for the control plane availability...
[✔]  saved kubeconfig as "/Users/smcllc/.kube/config"
[ℹ]  no tasks
[✔]  all EKS cluster resources for "nlw" have been created
[ℹ]  adding identity "arn:aws:iam::redacted:role/eksctl-nlw-nodegroup-ng-1-NodeInstanceRole-redacted" to auth ConfigMap
[ℹ]  nodegroup "ng-1" has 0 node(s)
[ℹ]  waiting for at least 1 node(s) to become ready in "ng-1"
[ℹ]  nodegroup "ng-1" has 1 node(s)
[ℹ]  node "ip-172-redacted.us-east-2.compute.internal" is ready
[ℹ]  kubectl command should work with "/Users/smcllc/.kube/config", try 'kubectl get nodes'
[✔]  EKS cluster "nlw" in "us-east-2" region is ready

LOCAL&gt;&gt;
</code></pre></div></div>

<p>We can check within AWS EKS and see if we have a new cluster:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image6.png" alt="alt_text" title="image_tooltip" /></p>

<p>nlw matches the name we gave to the cluster in the YAML file.</p>

<p>Let’s check to see if it has a node group:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image7.png" alt="alt_text" title="image_tooltip" /></p>

<p>Check the see if the cluster is working from the command line using kubectl:</p>

<blockquote>
  <blockquote>
    <p>kubectl cluster-info</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Kubernetes master is running at https://redacted.yl4.us-east-2.eks.amazonaws.com

CoreDNS is running at https://redacted.yl4.us-east-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
</code></pre></div></div>

<p>By looking at the EC2 dashboard, you can see the mx5.xlarge EC2 instance created for the cluster:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image8.png" alt="alt_text" title="image_tooltip" /></p>

<p>Now that we have a cluster, we need a back end database so that we can set up Neoload Web to store all the data. Keep in mind that even if you have to take down the FE and BE, or even start them back up from scratch, all the data is in the database, so you won’t lose anything.</p>

<h2 id="create-a-mongodb">Create A MongoDB</h2>

<p>We need a Mongo Database for the Neoload Web Back End (BE) to use. We will use Mongodb Atlas to do this. MongoDB Atlas is a global cloud database service fully managed MongoDB across AWS, Google Cloud, and Azure. This gives us the ability to deploy, run, and scale MongoDB in the cloud. For more information, see <a href="https://www.mongodb.com/cloud/atlas">https://www.mongodb.com/cloud/atlas</a></p>

<p>Ensure to follow good security practices and set up appropriate user access. Do not use the default security. Keep in mind that passwords that use special characters will be URL encoded, which may cause problems. You will also want to whitelist only IP addresses that you want to access the database, and no others.</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image9.png" alt="alt_text" title="image_tooltip" /></p>

<p>Set up a dedicated cluster, not a shared cluster. Ensure the version is 4.0 and no later.</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image10.png" alt="alt_text" title="image_tooltip" /></p>

<p>If you click the “connect” button, you will see the various ways that can be used to connect. Look at the string and use this as the information for the mongo host name in the section titled, “Deploy Helm File”.</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image11.png" alt="alt_text" title="image_tooltip" /></p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image12.png" alt="alt_text" title="image_tooltip" /></p>

<p>Choose “Connect Your Application” and select JAVA 3.4 or later</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image13.png" alt="alt_text" title="image_tooltip" /></p>

<p>The string below has the information we need for the mongodb hostname:</p>

<p>mongodb://neoloadweb:<password>@**cluster0-shard-00-00.redacted.mongodb.net:27017,cluster0-shard-00-01.redacted.mongodb.net:27017,cluster0-shard-00-02.redacted.mongodb.net:27017/<dbname>?ssl=true**&amp;replicaSet=atlas-redacted-shard-0&amp;authSource=admin&amp;retryWrites=true&amp;w=majority</dbname></password></p>

<p>Note that we are referencing each shard with a port, and the database name (we can use admin). We also have to set ssl=true for it to work. This is a requirement by Mongo Atlas. We will have to address this when we create a custom YAML file in the section titled, “Deploy the Helm chart”.</p>

<p>We set up a user id and password for accessing the database:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image14.png" alt="alt_text" title="image_tooltip" /></p>

<p>We added a user called neoloadweb and set a password. We will use this information in our YAML file when we run the command in the section “Deploy the Helm chart”.</p>

<p>We will want to whitelist only the IP address(es) needed for connections to the database, and deny all others. The easiest way to find the IP the EKS cluster will use for external outbound traffic is to look at the Elastic IP menu on AWS:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image15.png" alt="alt_text" title="image_tooltip" /></p>

<p>This IP address is automatically assigned to the cluster during creation unless you specify that it not be public and private only.</p>

<p>In Mongo Atlas, we set a whitelist filter with this IP address:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image16.png" alt="alt_text" title="image_tooltip" /></p>

<h2 id="install-the-ingress-controller">Install The Ingress Controller</h2>

<p>The ingress controller component sits inside the cluster and watches for deployments (such as NeoLoad Web) that are annotated in such a way to indicate that we need an AWS load balancer to provide an entry point for accessing NeoLoad Web via your browser. When it senses these annotations, it will create the appropriate AWS load balancer automatically.</p>

<p>Because we’re going to be using an NGINX ingress to route the three hostnames to the proper pod services, and we want our cluster to create an AWS NLB based on the annotations in our helm config file, we will need to install the AWS NGINX ingress controller. Essentially, it’s a side deployment that sits and waits for deployments with the right annotations to show up, then it creates the AWS NLB automatically.</p>

<p><a href="https://aws.amazon.com/blogs/opensource/network-load-balancer-nginx-ingress-controller-eks/">https://aws.amazon.com/blogs/opensource/network-load-balancer-nginx-ingress-controller-eks/</a></p>

<blockquote>
  <blockquote>
    <p>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-0.32.0/deploy/static/provider/aws/deploy.yaml</p>
  </blockquote>
</blockquote>

<blockquote>
  <blockquote>
    <p>kubectl get pods -n ingress-nginx</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                        READY   STATUS      RESTARTS   AGE
ingress-nginx-admission-create-redacted        0/1     Completed   0          59m
ingress-nginx-admission-patch-redacted         0/1     Completed   1          59m
ingress-nginx-controller-redacted   1/1     Running     0          59m
</code></pre></div></div>

<p>To verify what IP is being used by the ingress controller, You can remote into the nginx controller and run a command (like curl):</p>

<blockquote>
  <blockquote>
    <p>kubectl exec -it -n ingress-nginx ingress-nginx-controller-redacted  – sh /etc/nginx $ curl ifconfig.me</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3.139.107.100
</code></pre></div></div>

<p>This would tell you that IP 3.139.107.100 is the one being used to the outside world, and should match the one listed in Elastic IP’s for that cluster.</p>

<h2 id="install-neoload-web">Install NeoLoad Web</h2>

<p>Using these instructions:</p>

<p><a href="https://github.com/Neotys-Labs/helm-neoload-web">https://github.com/Neotys-Labs/helm-neoload-web</a></p>

<p><a href="https://github.com/paulsbruce/neoload_kube/blob/master/helm/post_cluster_nlw.md">https://github.com/paulsbruce/neoload_kube/blob/master/helm/post_cluster_nlw.md</a></p>

<p>We have already created a Kubernetes Cluster and a Mongodb. We already have the Helm CLI installed. All that remains is deploying the Helm chart to install the Neoload Web FE and BE containers into the cluster node group. Instead of installing the containers into the DEFAULT namespace, we want to create a distinct namespace just for Neoload Web.</p>

<p>Check the list of namespaces</p>

<blockquote>
  <blockquote>
    <p>kubectl get ns</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME              STATUS   AGE
default           Active   6d22h
ingress-nginx     Active   6d3h
kube-node-lease   Active   6d22h
kube-public       Active   6d22h
kube-system       Active   6d22h
</code></pre></div></div>

<p>Create a new namespace called neoloadweb:</p>

<blockquote>
  <blockquote>
    <p>kubectl create ns neoloadweb</p>
  </blockquote>
</blockquote>

<p>relist:</p>

<blockquote>
  <blockquote>
    <p>kubectl get ns</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME              STATUS   AGE
default           Active   6d22h
ingress-nginx     Active   6d3h
kube-node-lease   Active   6d22h
kube-public       Active   6d22h
kube-system       Active   6d22h
**neoloadweb      Active   81m**
</code></pre></div></div>

<p>If you still don’t see one, the previous command failed.</p>

<p>If you see the new namespace, change the context to the neoloadweb namespace so that when we deploy the containers they will be in this namespace</p>

<blockquote>
  <blockquote>
    <p>kubectl config set-context –current –namespace=neoloadweb</p>
  </blockquote>
</blockquote>

<h2 id="deploy-helm-chart">Deploy Helm Chart</h2>

<p>Add the Neotys chart repository:</p>

<p>helm repo add neotys https://helm.prod.neotys.com/stable/</p>

<p>Download and set up your values-custom.yaml file</p>

<p><a href="https://raw.githubusercontent.com/Neotys-Labs/helm-neoload-web/master/values-custom.yaml">https://raw.githubusercontent.com/Neotys-Labs/helm-neoload-web/master/values-custom.yaml</a></p>

<p>For the Mongo section, we used the values we got earlier from Mongo Altas for host name, userid, and password:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### NLWeb configuration
neoload:
 configuration:
   backend:
     mongo:
       host: cluster0-shard-00-02.redacted.mongodb.net:27017,cluster0-shard-00-00.redacted.mongodb.net:27017,cluster0-shard-00-01.redacted.mongodb.net:27017/admin?ssl=true
       port: 0
   # The secret key must be at least 8 characters long
   secretKey: neoloadweb

### MongoDB user configuration
mongodb:
 usePassword: true
 mongodbUsername: neoloadweb
 mongodbPassword: &lt;secret&gt;
</code></pre></div></div>

<p>We are using the information from the Mongo Atlas configuration section to put in the proper values into the mongo section of the YAML file:</p>

<p><em>cluster0-shard-00-02.redacted.mongodb.net:27017,cluster0-shard-00-00.redacted.mongodb.net:27017,cluster0-shard-00-01.redacted.mongodb.net:27017/admin?ssl=true</em></p>

<p>Because of this way of referencing the host, we need to set the <strong>port</strong> value in the YAML to 0 since the port is referenced and handled by the **host **connection string.</p>

<p>The secretKey is something we designate. In this example, we are using neoloadweb for simplicity’s sake.</p>

<p>The Services host configuration needs to reflect the DNS routing discussed in the section below titled, “Route DNS Requests To Neoload Web”.</p>

<p>The original</p>

<h3 id="services-host-configuration">Services host configuration</h3>

<p>services:</p>

<p>webapp:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>host: **neoload-web.mycompany.com**
</code></pre></div></div>

<p>api:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>host: **neoload-web-api.mycompany.com**
</code></pre></div></div>

<p>files:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>host: **neoload-web-files.mycompany.com**
</code></pre></div></div>

<p>What we used:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Services host configuration
services:
 webapp:
   host: neoload-web.load.redacted.com
 api:
   host: neoload-web-api.load.redacted.com
 files:
   host: neoload-web-files.load.redacted.com
</code></pre></div></div>

<p>Use the helm CLI to spin up the Neoload Web front end (FE) and back end (FE) containers into the cluster with the following command:</p>

<p>helm install nlw neotys/nlweb -f ./values-custom.yaml</p>

<p>In this example, we have named it nlw, but you can name it anything you like. When running this helm command, it already has the context of the current cluster and knows to deploy the containers to that EKS specific cluster. This is why you don’t have to designate the cluster name in the command arguments or have a reference to it in the YAML file.</p>

<p>As you deploy Neoload Web, you can monitor what is happening at various levels. First find out what the new POD name is that is being deployed using kubctl</p>

<blockquote>
  <blockquote>
    <p>kubectl get pods</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                READY   STATUS    RESTARTS   AGE
neoloadweb-redacted   0/2     Running   0          4s
</code></pre></div></div>

<p>To see the individual images deployed into the neoloadweb-redacted pod:</p>

<blockquote>
  <blockquote>
    <p>kubectl get pods –namespace=neoloadweb -o=jsonpath=”{..image}”</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>neotys/**neoload-web-backend**:latest neotys/**neoload-web-frontend**:latest neotys/neoload-web-backend:latest neotys/neoload-web-frontend:latestLOCAL&gt;&gt;
</code></pre></div></div>

<p>This shows we have both of the containers pulled from the latest image available.</p>

<p>Check the logs for the Neoload Web back end container and make sure it is connecting to the Mongodb database and coming up properly:</p>

<blockquote>
  <blockquote>
    <p>kubectl logs neoloadweb-nlweb-redacted nlweb-backend</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Starting mode START_MODE=ON_PREMISE
Starting Jetty on port 9092
Memory Allocation: Xmx2000m
Vertx IP Bus Address: 192.168.xxx.xxx public host 192.168.xxx.xxx
19:54:42,600 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Found resource [conf/logback-prod.xml] at [file:/server/conf/logback-prod.xml]
…
…
</code></pre></div></div>

<p>The  logs will have a lot of information in them. You want to look for errors/exceptions.  For example, this is a statement about not being able to connect to the database:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO  org.mongodb.driver.cluster - No server chosen by com.mongodb.async.client.ClientSessionHelper$1@4redacteda from cluster description ClusterDescription{type=UNKNOWN, connectionMode=SINGLE, serverDescriptions=[ServerDescription{address=**cluster0.redacted.mongodb.net**:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketReadException: Exception receiving message}, caused by {java.io.IOException: The connection to the server was closed}}]}. Waiting for 30000 ms before timing out
</code></pre></div></div>

<p>This specific error was because we originally tested the connection string with a different value than what mongoo was expecting and we did not have the SSL option turned on.</p>

<p>If you need to uninstall everything and fix any issues and do it over you can uninstall with the following command:</p>

<blockquote>
  <blockquote>
    <p>helm uninstall neoloadweb</p>
  </blockquote>
</blockquote>

<p>Obviously, use the same name used during the install command.</p>

<p>Too see more details about a deployment:</p>

<blockquote>
  <blockquote>
    <p>kubectl get deployment <deployment name=""> -o yaml</deployment></p>
  </blockquote>
</blockquote>

<p>You may have to edit the deployment manually to ensure the PORT value is set to 0 (zero):</p>

<blockquote>
  <blockquote>
    <p>kubectl edit deploy neoloadweb-nlweb</p>
  </blockquote>
</blockquote>

<p>This does a live edit of the YAML file deployed for the cluster. Look for the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spec:
  containers:
  - env:
    - name: PRODUCT_VERSION
      value: 2.6.0
    - name: MEMORY_MAX
      value: 2000m
    - name: MONGODB_HOST
      value: cluster0-shard-00-02.redacted.mongodb.net:27017,cluster0-shard-00-00.redacted.mongodb.net:27017,cluster0-shard-00-01.redacted.mongodb.net:27017/admin?ssl=true
    - name: MONGODB_PORT
      value: "27017"
    - name: MONGODB_LOGIN
      valueFrom:
        secretKeyRef:
...
</code></pre></div></div>

<p>Change the value for
  value: “27017”
to
  value: “0”</p>

<p>Use the same commands as with the <strong>vi</strong> editor in UNIX systems to get around and make changes.</p>

<p><strong>vi Editor cheat sheet:</strong></p>

<p><a href="http://www.atmos.albany.edu/daes/atmclasses/atm350/vi_cheat_sheet.pdf">http://www.atmos.albany.edu/daes/atmclasses/atm350/vi_cheat_sheet.pdf</a></p>

<p><strong>Note:</strong> <em>This value needs to be updated in this case because of the value NOT updating properly when deployed. This issue may be fixed in future releases. If the value is already zero, no changes are needed.</em></p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image17.png" alt="alt_text" title="image_tooltip" /></p>

<p>The EKS Cluster created contains a single Node Group. The Node Group has a single Node. Within this node, there are multiple namespaces (including the one we created called neoloadweb):</p>

<ul>
  <li>default</li>
  <li>ingress-nginx</li>
  <li>kube-node-lease</li>
  <li>kube-public</li>
  <li>kube-system</li>
  <li>neoloadweb</li>
</ul>

<p>The neoloadweb namespace has a single pod with two containers (the front end and the back end for Neoload Web). The DEFAULT namespace contains nothing. The ingress-nginx namespace contains the ingress-nginx-controller-redacted pod. The kube-node-lease</p>

<p>and kube-public namespaces contain nothing.</p>

<p>The <strong>kube-system</strong> namespace contains the following pods:</p>

<ul>
  <li><strong>aws-node</strong>-redacted - A DaemonSet that deploys one pod to each Amazon EC2 node in your cluster. The pod runs the Amazon Virtual Private Cloud (Amazon VPC) CNI controller, which provides VPC networking functionality to the pods and nodes in the cluster.</li>
  <li><strong>coredns</strong>-redacted-redacted - this is a DNS server. Pods running inside the Amazon EKS cluster use the CoreDNS service’s cluster IP as the default name server for querying internal and external DNS records. There are two of these listed in this cluster.</li>
  <li><strong>coredns</strong>-redacted2-redacted2 - this is a DNS server. Pods running inside the Amazon EKS cluster use the CoreDNS service’s cluster IP as the default name server for querying internal and external DNS records. There are two of these listed in this cluster.</li>
  <li><strong>kube-proxy</strong>-redacted - a network proxy that runs on each node in the cluster. It maintains network rules on nodes. These network rules allow network communication to your Pods from network sessions inside or outside of your cluster.</li>
</ul>

<h2 id="routing-dns-requests-to-neoload-web">Routing DNS Requests To Neoload Web</h2>

<p>The EKS cluster has a Load Balancer in AWS. This was created during EKS cluster creation. kubectl interacts with the EKS ALB for the cluster commands which we execute in the command line. See the section titled “Install The Ingress Controller” for more information.</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image18.png" alt="alt_text" title="image_tooltip" /></p>

<p>Note that we have a DNS name for the load balancer of</p>

<p>redacted.f.elb.us-east-2.amazonaws.com</p>

<p>However, if we try to go there directly in the browser, we will not get to the Neoload Web page. Instead we get a 404 Not Found page form NGINX:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image19.png" alt="alt_text" title="image_tooltip" /></p>

<p>Why? Because the ingress controller will only route requests to those host names.</p>

<p>Use this command to see the ingress and ingress controller settings:</p>

<p>k get ingress neoloadweb-nlweb-ingress -o yaml</p>

<p>you will see in the yaml the host names we provided:</p>

<p>spec:</p>

<p>rules:</p>

<ul>
  <li>
    <p>host: <strong>neoload-web-api.load.redacted.com</strong></p>

    <p>http:</p>

    <p>paths:</p>

    <ul>
      <li>
        <p>backend:</p>

        <p>serviceName: neoloadweb-nlweb-svc-api</p>

        <p>servicePort: 80</p>

        <p>pathType: ImplementationSpecific</p>
      </li>
    </ul>
  </li>
  <li>
    <p>host: <strong>neoload-web-files.load.redacted.com</strong></p>

    <p>http:</p>

    <p>paths:</p>

    <ul>
      <li>
        <p>backend:</p>

        <p>serviceName: neoloadweb-nlweb-svc-files</p>

        <p>servicePort: 80</p>

        <p>pathType: ImplementationSpecific</p>
      </li>
    </ul>
  </li>
  <li>
    <p>host: <strong>neoload-web.load.redacted.com</strong></p>

    <p>http:</p>

    <p>paths:</p>

    <ul>
      <li>
        <p>backend:</p>

        <p>serviceName: neoloadweb-nlweb-svc-webapp</p>

        <p>servicePort: 80</p>

        <p>pathType: ImplementationSpecific</p>
      </li>
    </ul>
  </li>
</ul>

<p>It has to be able to resolve to the Load Balancer IP and HTTP requests must have the right host in the HTTP resource URI that allows the cluster to resolve to the right route/service.</p>

<p>How do we get  <strong>neoload-web.yourcompanyname.com</strong> routed to the front end of our Neoload Web instance?</p>

<p>This depends on how your company handles DNS routing. If you are doing this yourself, you might use the Route 53 service from AWS:</p>

<p><a href="https://aws.amazon.com/route53/">https://aws.amazon.com/route53/</a></p>

<p>This could also be handled by other services like Godaddy, Cloudflare, or other third party DNS services. Here is an example using Rackspace:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image20.png" alt="alt_text" title="image_tooltip" /></p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image21.png" alt="alt_text" title="image_tooltip" /></p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image22.png" alt="alt_text" title="image_tooltip" /></p>

<p>This screenshot shows neoload-web-files, and just needs to be repeated for the other two host names of neoload-web and neoload-web-api. They all point to the same DNS name listed in the AWS load balancer.</p>

<h2 id="verify-neoload-web">Verify Neoload Web</h2>

<p>Navigate to the same host URL that we defined in hour YAML file in a browser window:</p>

<p><strong>neoload-web.load.redacted.com</strong></p>

<p>You should see the main login window for Neoload Web. This indicates the routing is working correctly and the Neload Web application is available.</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image23.png" alt="alt_text" title="image_tooltip" />
** <br />
**From here, you can follow the online documentation for Neoload Web:</p>

<p><a href="https://www.neotys.com/documents/doc/nlweb/latest/en/html/#2983.htm">https://www.neotys.com/documents/doc/nlweb/latest/en/html/#2983.htm</a> ** <br />
**</p>

<p>When connecting the Neoload GUI to the Neoload Web server, be aware that all of the host names point to port 80, whereas other ports are used in other kinds of configurations. For example, port 8080 is typically used by the API access - used by the Neoload GUI. In this case, we are referencing a distinct URL of neoload-web-api.company.com on port 80 to access the API:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image24.png" alt="alt_text" title="image_tooltip" /></p>

<p>This is a change to the default URL connection input in the Neoload GUI. The same concept applies to the neoload-web-files URL.</p>

<p>If you wanted to spin up a Docker Load Generator to connect to this cluster you would use a command like this:</p>

<p>docker run -d –name=generator01 -p 7101:7100 -e NEOLOADWEB_TOKEN=redacted -e NEOLOADWEB_URL=http://neoload-web-api.redacted.com -e ZONE=redacted -e NEOLOADWEB_WORKSPACE=redacted -e LG_HOST=redacted IP address -e LG_PORT=7101 -e LOADGENERATOR_XMX=-Xmx2048m -e AGENT_XMX=-Xmx512m neotys/neoload-loadgenerator</p>

<p>It is recommended to use a different port for each Generator running on a VM host.</p>

<p>generator01 = 7101</p>

<p>generator02 = 7102</p>

<p>generator99 = 7199</p>

<p>Note that you should not need to add additional ports to be open at the AWS Security Group level.</p>

<h1 id="upgrade-neoload-web">Upgrade Neoload Web</h1>

<p>Periodically, the Neoload Web software will be updated by Neotys. The Helm chart used in these examples produces a deployment that has container specs which include ‘imagePullPolicy: Always’.</p>

<p>To get the name of the deployment:</p>

<blockquote>
  <blockquote>
    <p>kubectl get deployment</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
neoloadweb-nlweb   1/1     1            1           5d20h
</code></pre></div></div>

<p>Get the name of all pods</p>

<blockquote>
  <blockquote>
    <p>kubectl get pods -A</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAMESPACE       NAME                                        READY   STATUS    RESTARTS   AGE
ingress-nginx   ingress-nginx-controller-redacted   1/1     Running   0          4h30m
kube-system     aws-node-redacted                              1/1     Running   0          6d22h
kube-system     coredns-redacted                    1/1     Running   0          4h30m
kube-system     coredns-redacted                    1/1     Running   0          4h30m
kube-system     kube-proxy-redacted                            1/1     Running   0          6d22h
neoloadweb      neoloadweb-nlweb-redacted            2/2     Running   0          76m
</code></pre></div></div>

<p>To upgrade the containers within the EKS Cluster:</p>

<p>Ensure that scheduling is enabled:</p>

<p>Get the name of the node:</p>

<blockquote>
  <blockquote>
    <p>get nodes</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                          STATUS                     ROLES    AGE     VERSION
ip-redacted.us-east-2.compute.internal   Ready,**SchedulingDisabled**   &lt;none&gt;   6d17h   v1.18.9-eks-d1db3c
</code></pre></div></div>

<p>If you see in the STATUS column SchedulingDisabled, use the following command:</p>

<blockquote>
  <blockquote>
    <p>kubectl uncordon ip-redacted.us-east-2.compute.internal</p>
  </blockquote>
</blockquote>

<p>rerun get nodes and this should be removed</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                          STATUS                     ROLES    AGE     VERSION
ip-redacted.us-east-2.compute.internal   Ready    &lt;none&gt;   6d22h   v1.18.9-eks-d1db3c
</code></pre></div></div>

<blockquote>
  <blockquote>
    <p>kubectl describe node ip-redacted.us-east-2.compute.internal</p>
  </blockquote>
</blockquote>

<p>Check the list of namespaces and make sure you have one for neoloadweb</p>

<blockquote>
  <blockquote>
    <p>kubectl get ns</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME              STATUS   AGE
default           Active   6d22h
ingress-nginx     Active   6d3h
kube-node-lease   Active   6d22h
kube-public       Active   6d22h
kube-system       Active   6d22h
</code></pre></div></div>

<p>If not, create one. Otherwise, skip this step:</p>

<blockquote>
  <blockquote>
    <p>kubectl create ns neoloadweb</p>
  </blockquote>
</blockquote>

<p>relist:</p>

<blockquote>
  <blockquote>
    <p>kubectl get ns</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME              STATUS   AGE
default           Active   6d22h
ingress-nginx     Active   6d3h
kube-node-lease   Active   6d22h
kube-public       Active   6d22h
kube-system       Active   6d22h
neoloadweb        Active   81m
</code></pre></div></div>

<p>Change the context to the neoloadweb namespace</p>

<blockquote>
  <blockquote>
    <p>kubectl config set-context –current –namespace=neoloadweb</p>
  </blockquote>
</blockquote>

<blockquote>
  <blockquote>
    <p>kubectl rollout restart deployment/neoloadweb-nlweb</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>deployment.apps/neoloadweb-nlweb restarted
</code></pre></div></div>

<p>To query the progress of the new deployment:</p>

<blockquote>
  <blockquote>
    <p>kubectl get pods</p>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                READY   STATUS    RESTARTS   AGE
neoloadweb-nlweb-redacted    2/2     Running   0          5d20h
neoloadweb-nlweb-redacted   0/2     Pending   0          30s
</code></pre></div></div>

<p>You will see the old deployment (the one with the longer AGE value) change over time as you run this same query.</p>

<p>This will do a “rolling restart” of the neoload web deployment and cause kube master to spin up a new pod with the latest front/back versions, then drain the old pod. This may take several minutes. You can confirm what version of Neoload Web is running by either checking the Neoload Web login page:</p>

<p><img src="/_pages/tutorials/deploying-neoload-web-in-aws/images/image25.png" alt="alt_text" title="image_tooltip" /></p>

<p>OR using the kubectl command to look for the version of the current pods.</p>

<blockquote>
  <blockquote>
    <table>
      <tbody>
        <tr>
          <td>kubectl describe pods</td>
          <td>grep PRODUCT_VERSION:</td>
        </tr>
      </tbody>
    </table>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PRODUCT_VERSION:                        **2.6.0**

      PRODUCT_VERSION:  **2.6.0**
</code></pre></div></div>

<p>The version number should be higher than the one previously installed. Note that Neotys may release version updates to Neoload GUI and the docker container images for Controllers and Generators at dockerhub.com separately from the Neoload Web container images. Verify that new Neoload Web images have been released before performing an upgrade.</p>

<p>To see all containers in the pod:</p>

<blockquote>
  <blockquote>
    <table>
      <tbody>
        <tr>
          <td>kubectl get pods –all-namespaces -o jsonpath=”{..image}”</td>
          <td>\</td>
        </tr>
      </tbody>
    </table>
  </blockquote>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tr -s '[[:space:]]' '\n' |\
sort |\
uniq -c
   2 redacted.us-east-2.amazonaws.com/amazon-k8s-cni-init:v1.7.5-eksbuild.1
   2 redacted.ecr.us-east-2.amazonaws.com/amazon-k8s-cni:v1.7.5-eksbuild.1
   4 redacted.us-east-2.amazonaws.com/eks/coredns:v1.7.0-eksbuild.1
   2 redacted.us-east-2.amazonaws.com/eks/kube-proxy:v1.18.8-eksbuild.1
   4 jettech/kube-webhook-certgen:v1.2.0
   2 neotys/neoload-web-backend:latest
   2 neotys/neoload-web-frontend:latest
   2 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.32.0
</code></pre></div></div>

<p>If the rolling update does not work, use help to uninstall and reinstall:</p>

<blockquote>
  <blockquote>
    <p>helm uninstall neoloadweb</p>
  </blockquote>
</blockquote>

<blockquote>
  <blockquote>
    <p>helm install neoloadweb neotys/nlweb -f ./values-custom.yaml</p>
  </blockquote>
</blockquote>

<p>To see a status:</p>

<blockquote>
  <blockquote>
    <p>kubectl get pods -A</p>
  </blockquote>
</blockquote>

<p>Ensure they are all running</p>






  </div>
  <div class="article-sidebar">



  <h3>Contributors</h3>
  <ul>
  <li>




<a href="https://qaconsultants.com/" title="QA Consultants" target="_blank">QA Consultants</a>
</li>
  <li>




<a href="http://scottmoore.consulting" title="Scott Moore" target="_blank">Scott Moore</a>
</li>
  <li>




<a href="https://github.com/paulsbruce" title="Paul Bruce" target="_blank">Paul Bruce</a>
</li>
  
  </ul>


<p style="font-size:0.8em">

  
  Supported by Community
  <br />(not Neotys officially)
  

</p>






  <p>
  <h3>Videos</h3>
  
    
      <iframe width="280" height="157" src="https://www.youtube.com/embed/Ui9LFbKX5zU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    
  
  </p>



  <div class="toc">
  <p>
  <h3>ToC</h3>
  <ul>
  <li><a href="#the-short-version">The Short Version</a></li>
  <li><a href="#the-complete-walkthrough">The Complete Walkthrough</a></li>
  <li><a href="#before-you-begin">Before you begin</a></li>
  <li><a href="#what-is-amazon-eks">What is Amazon EKS?</a></li>
  <li><a href="#cli-and-prerequisite-installation">CLI and Prerequisite Installation</a>
    <ul>
      <li><a href="#aws-cli-v2">AWS CLI v2</a></li>
      <li><a href="#helm">helm</a></li>
      <li><a href="#eksctl-and-kubectl">eksctl and kubectl</a></li>
    </ul>
  </li>
  <li><a href="#neoload-web">Neoload Web</a></li>
  <li><a href="#deploy-neoload-web">Deploy Neoload Web</a>
    <ul>
      <li><a href="#create-the-eks-cluster">Create The EKS Cluster</a></li>
      <li><a href="#create-a-mongodb">Create A MongoDB</a></li>
      <li><a href="#install-the-ingress-controller">Install The Ingress Controller</a></li>
      <li><a href="#install-neoload-web">Install NeoLoad Web</a></li>
      <li><a href="#deploy-helm-chart">Deploy Helm Chart</a>
        <ul>
          <li><a href="#services-host-configuration">Services host configuration</a></li>
        </ul>
      </li>
      <li><a href="#routing-dns-requests-to-neoload-web">Routing DNS Requests To Neoload Web</a></li>
      <li><a href="#verify-neoload-web">Verify Neoload Web</a></li>
    </ul>
  </li>
  <li><a href="#upgrade-neoload-web">Upgrade Neoload Web</a></li>
</ul>

  </p>
  </div>



  </div>


</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>

<!-- env: development -->
</body>

</html>
